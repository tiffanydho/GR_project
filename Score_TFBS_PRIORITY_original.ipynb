{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Method 2 Site caller \n",
        "(ALPHA version 1)\n",
        "\n",
        "Author: Zachery Mielko\n",
        "\n",
        "The script requires the following dependencies:\n",
        "- Python modules:\n",
        "    - pandas\n",
        "    - numpy\n",
        "    - biopython\n",
        "- Command line tools:\n",
        "    - Bedtools\n",
        "\n",
        "\n",
        "Method 2 takes in the following as **input**:\n",
        "\n",
        "- Human Genome file (FASTA, must have an index file in the same directory, .fai\n",
        "    - You can get this from Samtools faidx\n",
        "- Alignment file from PRIORITY\n",
        "- Chip-seq peaks (BED file)\n",
        "\n",
        "The script gives the following as **output**:\n",
        "- Bed file of centered sites (Centered_PRIORITY.bed)\n",
        "\n",
        "The output as-is will just be the 1bp center, but you could extract the whole match, which is calculated. \n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "################## User defined ###############\n",
        "# Folder for input/output\n",
        "IO_Folder = \"/Users/ZMielko/Desktop/In_Vivo_Project/Cistrome_Analysis/Ets1/Ets1_PRIORITY/\"\n",
        "# File that has Encode/called peaks\n",
        "Data_file = 'Ets1DHSv2promoterHg19NoDac.bed'\n",
        "# Prior assumptions about the kmer PRIORITY alignment\n",
        "core = [7,13] \n",
        "center_pos = 10\n",
        "\n",
        "################# Common Parameters ###########\n",
        "# Human genome fasta file\n",
        "Genome_file = '/Users/ZMielko/Desktop/In_Vivo_Project/Data/human_g1k_v37.fasta'\n",
        "Overlap_Req = 2\n",
        "Threshold = 0.45 # Name only for saving\n",
        "# Output_file_names\n",
        "Called_TFBS_Save = f\"{IO_Folder}/Called_TFBS_{str(Threshold)}\" # Called sites\n",
        "Centered_TFBS_Save = f\"{IO_Folder}/Centered_TFBS_{str(Threshold)}.bed\" # Centered sites in bed format\n",
        "Centered_TFBS_Verbose = f\"{IO_Folder}/Centered_TFBS_Verbose_{str(Threshold)}.bed\" # Centered sites, with scoring and site information\n",
        "kmer_length = 7\n",
        "#################################################\n",
        "\n",
        "###########\n",
        "# Imports #\n",
        "###########\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "from Bio import SeqIO\n",
        "import os\n",
        "import re\n",
        "from Bio.Seq import reverse_complement\n",
        "\n",
        "### kmer prep ###\n",
        "# Some function requires kmers to be defined. SO this code defines the kmers from the PRIORITY alignment\n",
        "kmers = pd.read_csv(f'{IO_Folder}/Ets1_45_PRIORITY.txt', sep = '\\t')\n",
        "iscore = []\n",
        "position = []\n",
        "kmer = []\n",
        "for i in kmers['sequences']:\n",
        "    if '.' in i[core[0]:core[1]]:\n",
        "        iscore.append(False)\n",
        "    else:\n",
        "        iscore.append(True)\n",
        "    position.append(re.search('(C|G|A|T)',i).start())\n",
        "    kmer.append(re.findall('[A-Z]{' + str(kmer_length) + '}',i)[0])\n",
        "kmers['is_core'] = iscore\n",
        "kmers['kPosition'] = position\n",
        "kmers['kmer'] = kmer\n",
        "\n",
        "#############\n",
        "# Functions #\n",
        "#############\n",
        "\n",
        "def DF_fasta(x):\n",
        "    pos = x[x[0].str.startswith('>')]\n",
        "    pos = pos.reset_index(drop=True)\n",
        "    seqs = x[~x[0].str.startswith('>')]\n",
        "    seqs = seqs.reset_index(drop=True)\n",
        "    new = pd.DataFrame({'Position':pos[0],'Sequence':seqs[0]})\n",
        "    return(new)\n",
        "  \n",
        "def read_fasta(file):\n",
        "  records = []\n",
        "  sequence = []\n",
        "  with open(file, \"rU\") as handle:\n",
        "      for record in SeqIO.parse(handle, \"fasta\"):\n",
        "        records.append(record.id)\n",
        "        sequence.append(str(record.seq))\n",
        "  Whole_seqs = pd.DataFrame({'Name':records,'Sequence':sequence})\n",
        "  return Whole_seqs\n",
        "\n",
        "\n",
        "\n",
        "def kmer_match(String, window,kmer_list, Item):\n",
        "    \"\"\"kmer_match takes a string and scans along it to match the score with E-scores\"\"\"\n",
        "    seq_list = []\n",
        "    pos_list = []\n",
        "    for i in range(len(String) - (window-1)):\n",
        "        seq = String[i:i+window]\n",
        "        pos = i\n",
        "        if seq in kmer_list:\n",
        "            seq_list.append(seq)\n",
        "            pos_list.append(pos)\n",
        "    result = pd.DataFrame({'Seq':seq_list,'Position':pos_list,'Peak_Seq':Item})\n",
        "    return(result)\n",
        "\n",
        "\n",
        "def Score_Blaster(x, kmerSeqs,Thresh=Threshold, kmer_length = kmer_length):\n",
        "    \"\"\"Score_Blaster applies kmer_match to a dataframe. Only gives scores above a threshold, zip version\"\"\"\n",
        "    DataFrames = []\n",
        "    print('Total length: ' + str(len(x)))\n",
        "    for index,row in enumerate(zip(x['Sequence'], x['Position'])):\n",
        "      # Counter to keep track of progress\n",
        "      if int(index)%5000 == 0:\n",
        "        print(index)\n",
        "      # kmer match function \n",
        "      DataFrames.append(kmer_match(row[0], kmer_length, kmerSeqs,  row[1]))\n",
        "    result = pd.concat(DataFrames)\n",
        "    return(result)\n",
        "\n",
        "def Site_Caller(x):\n",
        "  \"\"\" Siter caller looks for consecutive overlaps \"\"\"\n",
        "  Groups = []\n",
        "  PrevPos = x['Position'][0] -1\n",
        "  PrevSeq = x['Peak_Seq'][0]\n",
        "  SeqNumber = 0\n",
        "  for idx,row in enumerate(zip(x['Peak_Seq'],x['Position'])):\n",
        "    # When a new Sequence is being read\n",
        "    if str(row[0]) != str(PrevSeq):\n",
        "      PrevSeq = str(row[0])\n",
        "      PrevPos = row[1]\n",
        "      SeqNumber = SeqNumber + 1\n",
        "      Groups.append(SeqNumber)\n",
        "    # When you have a consecutive position\n",
        "    elif row[1] - PrevPos == 1:\n",
        "      Groups.append(SeqNumber)\n",
        "      PrevPos = row[1]\n",
        "    # When you have a non-consecutive position\n",
        "    elif row[1] - PrevPos != 1:\n",
        "      PrevPos = row[1]\n",
        "      SeqNumber = SeqNumber + 1\n",
        "      Groups.append(SeqNumber)\n",
        "  return(Groups)\n",
        "\n",
        "\n",
        "def Chrom_Splitter(x):\n",
        "    \"\"\"Chrom_Splitter takes the concatinated names given in fasta outputs from bedtool's getfasta and turns them into bed compatible columns\"\"\"\n",
        "    Chrom = []\n",
        "    Start = []\n",
        "    End = []\n",
        "    for i in x.Peak_Seq:\n",
        "        i = i[1:-2]\n",
        "        cr = i.split(':')\n",
        "        pos = cr[1].split('-')\n",
        "        Chrom.append(cr[0])\n",
        "        Start.append(int(pos[0]))\n",
        "        End.append(int(pos[1]))\n",
        "    x['Chromosome'] = Chrom\n",
        "    x['Start'] = Start\n",
        "    x['End'] = End\n",
        "    return(x)\n",
        "\n",
        "def Genomic_Adjuster(x,orient, kmer_length=kmer_length):\n",
        "    g = x.groupby(by=['Peak_Seq', 'Site_number'])\n",
        "    Site_Start = []\n",
        "    Site_End = []\n",
        "    Chrom = []\n",
        "    Center = []\n",
        "    for name, group in g:\n",
        "        if orient == '+':\n",
        "            group_start = int(min(group.Position_x)) + int(group.Start.unique())\n",
        "            group_end = int(max(group.Position_x)) + int(group.Start.unique()) + kmer_length\n",
        "            group_center = (center_pos - int(min(group.kPosition))) + int(group.Start.unique()) + int(min(group.Position_x))\n",
        "            Site_Start.append(group_start)\n",
        "            Site_End.append(group_end)\n",
        "            Center.append(group_center)\n",
        "            Chrom.append(group.Chromosome.unique()[0])\n",
        "        elif orient == '-':\n",
        "            slength = int(group.Length.unique())\n",
        "            group_end = int(slength - min(group.Position_x)) + int(group.Start.unique())\n",
        "            group_start = int(slength - max(group.Position_x) - kmer_length) + int(group.Start.unique()) \n",
        "            group_center = (slength - (center_pos - int(min(group.kPosition)) + int(min(group.Position_x)))) + int(group.Start.unique()) +1\n",
        "            Site_Start.append(group_start)\n",
        "            Site_End.append(group_end)\n",
        "            Center.append(group_center)\n",
        "            Chrom.append(group.Chromosome.unique()[0])\n",
        "    result = pd.DataFrame({'Chromosome':Chrom, \"Start\":Site_Start,\n",
        "             'End':Site_End, 'Center':Center, 'Orient':orient})\n",
        "    print(f\"Orientation selected is: {orient}\")\n",
        "    return(result)\n",
        "\n",
        "\n",
        "\n",
        "########################\n",
        "# Prepare For getfasta #\n",
        "########################\n",
        "# Adjust the \"Off by 1\" issue from bedtools due to the start site being exclusionary\n",
        "# Bash IO\n",
        "Bash_Input = IO_Folder + \"/Adjusted_peaks\"\n",
        "Bash_Genome = Genome_file\n",
        "Bash_Out = IO_Folder + '/PeaksWSeqs.fasta'\n",
        "\n",
        "# Read CSV, filter for short seqs and duplicates, adjust coordinates\n",
        "Peaks = pd.read_csv(IO_Folder + '/' + Data_file,\n",
        "                  sep = '\\t',\n",
        "                  header = None,\n",
        "                  usecols=[0,1,2]) \n",
        "Peaks = Peaks[Peaks[2]-Peaks[1] > (kmer_length+Overlap_Req)].drop_duplicates() # filter for short sequences the caller would have trouble with\n",
        "Peaks[1] = Peaks[1] -1 # Move back 1, adjust for bedtools getfasta\n",
        "Peaks.to_csv(Bash_Input,\n",
        "           sep = '\\t', index = False, header = None) #Output to getfasta\n",
        "\n",
        "# Run getFasta\n",
        "os.system(f'bedtools getfasta -s -fi {Bash_Genome} -bed {Bash_Input} > {Bash_Out} ')\n",
        "\n",
        "###################\n",
        "#* Data Analysis *#\n",
        "###################\n",
        "\n",
        "print(\"Reading Files...\")\n",
        "\n",
        "# Read fasta files\n",
        "PeaksWSeqs = pd.read_csv(Bash_Out, sep = '\\t', header=None)\n",
        "PeaksWSeqs = DF_fasta(PeaksWSeqs)\n",
        "PeaksWSeqs['Length'] = PeaksWSeqs['Sequence'].apply(lambda x: len(x))\n",
        "# Make a reverse complement of the sequences\n",
        "rc_PeaksWSeqs = PeaksWSeqs.copy(deep = True)\n",
        "rc_PeaksWSeqs['Sequence'] = rc_PeaksWSeqs['Sequence'].apply(lambda x: reverse_complement(x))\n",
        "# turn the kmers series into a set for fast lookup\n",
        "chosen_kmers = set(kmers['kmer'])\n",
        "# Big function of the analysis\n",
        "def PRIORITY_CALL(Sequences, orientation = '+'):\n",
        "    Scored = Score_Blaster(x=Sequences, kmerSeqs = chosen_kmers) #Score sites\n",
        "    Groups = Site_Caller(Scored) # Look for consecutive overlaps (consecutive in genome), groups are a unique value\n",
        "    Called = Scored.copy(deep = True) # make a copy\n",
        "    Called['Site_number'] = Groups # add overlap annotation to DF\n",
        "    print(\"Finding Overlaps...\")\n",
        "    # Get overlaps of sites with more than 1 consecutive overlap\n",
        "    values = Called.Site_number.value_counts() \n",
        "    Called = Called[Called.Site_number.isin(values.index[values.gt(Overlap_Req-1)])]\n",
        "    Called['Position'] = Called['Position'].apply(lambda x: int(x))\n",
        "    # Get the core kmers as a set. Core kmers are those that contain the core range\n",
        "    core_kmers = set(kmers[kmers['is_core']]['kmer'])\n",
        "    core_groups = []\n",
        "    # for each group, only keep it if it has a core kmer\n",
        "    for group in Called.groupby(by='Site_number'):\n",
        "        if len(set(group[1].Seq).intersection(core_kmers)) > 0:\n",
        "            core_groups.append(group[0])\n",
        "    # Get the core groups as a set, filter by core groups\n",
        "    core_groups = set(core_groups)\n",
        "    Called_core = Called[Called['Site_number'].isin(core_groups)]\n",
        "    # Add kPosition to the DF\n",
        "    Called2 = pd.merge(Called_core, kmers[['kmer','kPosition']], left_on = 'Seq', right_on='kmer')\n",
        "    Called2 = Called2.sort_values(by=['Site_number', 'Position'])\n",
        "    # Check that the kPosition is consecutive\n",
        "    def checkConsecutive(l): \n",
        "        return sorted(l) == l \n",
        "    con_groups = []\n",
        "    for group in Called2.groupby(by='Site_number'):\n",
        "        if checkConsecutive(list(group[1].kPosition)):\n",
        "            con_groups.append(group[0])\n",
        "    con_groups = set(con_groups)\n",
        "    Called2 = Called2[Called2['Site_number'].isin(con_groups)]\n",
        "    Called2 = pd.merge(Called2, PeaksWSeqs[['Position','Length']], left_on = 'Peak_Seq', right_on = 'Position')\n",
        "    Called3 = Chrom_Splitter(Called2)\n",
        "    final = Genomic_Adjuster(Called3, orient=orientation)\n",
        "    final = final.drop_duplicates()\n",
        "    return(final)\n",
        "# Run the function for positive and negative strands\n",
        "Positive = PRIORITY_CALL(PeaksWSeqs)\n",
        "Negative = PRIORITY_CALL(rc_PeaksWSeqs, orientation= '-')\n",
        "# Merge the results\n",
        "total = pd.concat([Positive,Negative])\n",
        "total['Start'] = total['Center']\n",
        "total['End'] = total['Center']\n",
        "total = total[['Chromosome', 'Start', 'End', 'Orient']]\n",
        "total.to_csv(f\"{IO_Folder}/Centered_PRIORITY.bed\", sep = '\\t', header = None, index = False)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "nteract": {
      "version": "0.14.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}