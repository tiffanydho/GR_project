{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2 Site caller \n",
    "(ALPHA version 1)\n",
    "\n",
    "Author: Zachery Mielko\n",
    "\n",
    "The script requires the following dependencies:\n",
    "- Python modules:\n",
    "    - pandas\n",
    "    - numpy\n",
    "    - biopython\n",
    "- Command line tools:\n",
    "    - Bedtools\n",
    "\n",
    "\n",
    "Method 2 takes in the following as **input**:\n",
    "\n",
    "- Human Genome file (FASTA, must have an index file in the same directory, .fai\n",
    "    - You can get this from Samtools faidx\n",
    "- Alignment file from PRIORITY\n",
    "- Chip-seq peaks (BED file)\n",
    "\n",
    "The script gives the following as **output**:\n",
    "- Bed file of centered sites (Centered_PRIORITY.bed)\n",
    "\n",
    "The output as-is will just be the 1bp center, but you could extract the whole match, which is calculated. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: conda [-h] [-V] command ...\n",
      "\n",
      "conda is a tool for managing and deploying applications, environments and packages.\n",
      "\n",
      "Options:\n",
      "\n",
      "positional arguments:\n",
      "  command\n",
      "    clean        Remove unused packages and caches.\n",
      "    config       Modify configuration values in .condarc. This is modeled\n",
      "                 after the git config command. Writes to the user .condarc\n",
      "                 file (/mnt/c/Users/th184/.condarc) by default.\n",
      "    create       Create a new conda environment from a list of specified\n",
      "                 packages.\n",
      "    help         Displays a list of available conda commands and their help\n",
      "                 strings.\n",
      "    info         Display information about current conda install.\n",
      "    init         Initialize conda for shell interaction. [Experimental]\n",
      "    install      Installs a list of packages into a specified conda\n",
      "                 environment.\n",
      "    list         List linked packages in a conda environment.\n",
      "    package      Low-level conda package utility. (EXPERIMENTAL)\n",
      "    remove       Remove a list of packages from a specified conda environment.\n",
      "    uninstall    Alias for conda remove.\n",
      "    run          Run an executable in a conda environment. [Experimental]\n",
      "    search       Search for packages and display associated information. The\n",
      "                 input is a MatchSpec, a query language for conda packages.\n",
      "                 See examples below.\n",
      "    update       Updates conda packages to the latest compatible version.\n",
      "    upgrade      Alias for conda update.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help     Show this help message and exit.\n",
      "  -V, --version  Show the conda version number and exit.\n",
      "\n",
      "conda commands available from other packages:\n",
      "  build\n",
      "  convert\n",
      "  debug\n",
      "  develop\n",
      "  env\n",
      "  index\n",
      "  inspect\n",
      "  metapackage\n",
      "  render\n",
      "  server\n",
      "  skeleton\n",
      "  verify\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "import re\n",
    "from Bio.Seq import reverse_complement\n",
    "\n",
    "################## User defined ###############\n",
    "# Folder for input/output\n",
    "##IO_Folder = \"/Users/ZMielko/Desktop/In_Vivo_Project/Cistrome_Analysis/Ets1/Ets1_PRIORITY/\"\n",
    "wkdir = r\"C:\\Users\\th184\\Box Sync\\Gordan Lab\\PRIORITY_score_caller\"\n",
    "TF = \"Elk1\"\n",
    "IO_Folder = os.path.join(wkdir, TF)\n",
    "# File that has Encode/called peaks\n",
    "##Data_file = 'Ets1DHSv2promoterHg19NoDac.bed'\n",
    "peak_coord_file = \"Elk1DHSv2promoterHg19NoDac.bed\"\n",
    "kmer_file = \"Elk1_kmers_45_PRIORITY_test.txt\"\n",
    "# Prior assumptions about the kmer PRIORITY alignment\n",
    "## how did you get this? also true for Elk1?\n",
    "core = [7,12]  # 0-indexed\n",
    "center_pos = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "################# Common Parameters ###########\n",
    "# Human genome fasta file\n",
    "genome_file = r\"C:\\Users\\th184\\Box Sync\\Probe Design\\hg19.fa\"\n",
    "Overlap_Req = 2\n",
    "Threshold = 0.45 # Name only for saving\n",
    "# Output_file_names\n",
    "Called_TFBS_Save = f\"{IO_Folder}/Called_TFBS_{str(Threshold)}\" # Called sites\n",
    "Centered_TFBS_Save = f\"{IO_Folder}/Centered_TFBS_{str(Threshold)}.bed\" # Centered sites in bed format\n",
    "Centered_TFBS_Verbose = f\"{IO_Folder}/Centered_TFBS_Verbose_{str(Threshold)}.bed\" # Centered sites, with scoring and site information\n",
    "kmer_length = 7\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "### kmer prep ###\n",
    "# Some function requires kmers to be defined. SO this code defines the kmers from the PRIORITY alignment\n",
    "kmers = pd.read_csv(f'{IO_Folder}/{kmer_file}', sep = '\\t') # created an Unnamed column for no reason\n",
    "kmers = kmers.loc[:, ~kmers.columns.str.contains('^Unnamed')] # get rid of the Unnamed column\n",
    "iscore = []\n",
    "position = []\n",
    "kmer = []\n",
    "for i in kmers['sequences']:\n",
    "    if '.' in i[core[0]:core[1]+1]: # added +1\n",
    "        iscore.append(False)\n",
    "    else:\n",
    "        iscore.append(True)\n",
    "    kPos = re.search('(C|G|A|T)',i).start() # 0-indexed\n",
    "    position.append(kPos) \n",
    "    kmer.append(i[kPos: kPos+kmer_length])\n",
    "    #kmer.append(re.findall('[A-Z]{' + str(kmer_length) + '}',i)[0])\n",
    "kmers['is_core'] = iscore\n",
    "kmers['kPosition'] = position\n",
    "kmers['kmer'] = kmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequences</th>\n",
       "      <th>orient</th>\n",
       "      <th>is_core</th>\n",
       "      <th>kPosition</th>\n",
       "      <th>kmer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>..........CGGACGT...</td>\n",
       "      <td>R</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>CGGACGT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.........CCGGACA....</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>CCGGACA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.......ATCCGAC......</td>\n",
       "      <td>F</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>ATCCGAC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sequences orient  is_core  kPosition     kmer\n",
       "0  ..........CGGACGT...      R    False         10  CGGACGT\n",
       "1  .........CCGGACA....      F    False          9  CCGGACA\n",
       "2  .......ATCCGAC......      F     True          7  ATCCGAC"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "#############\n",
    "# Functions #\n",
    "#############\n",
    "\n",
    "def DF_fasta(x):\n",
    "    pos = x[x[0].str.startswith('>')]\n",
    "    pos = pos.reset_index(drop=True)\n",
    "    seqs = x[~x[0].str.startswith('>')]\n",
    "    seqs = seqs.reset_index(drop=True)\n",
    "    new = pd.DataFrame({'Position':pos[0],'Sequence':seqs[0]})\n",
    "    return(new)\n",
    "  \n",
    "def read_fasta(file):\n",
    "  records = []\n",
    "  sequence = []\n",
    "  with open(file, \"rU\") as handle:\n",
    "      for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        records.append(record.id)\n",
    "        sequence.append(str(record.seq))\n",
    "  Whole_seqs = pd.DataFrame({'Name':records,'Sequence':sequence})\n",
    "  return Whole_seqs\n",
    "\n",
    "\n",
    "\n",
    "def kmer_match(String, window,kmer_list, Item):\n",
    "    \"\"\"kmer_match takes a string and scans along it to match the score with E-scores\"\"\"\n",
    "    seq_list = []\n",
    "    pos_list = []\n",
    "    for i in range(len(String) - (window-1)):\n",
    "        seq = String[i:i+window]\n",
    "        pos = i\n",
    "        if seq in kmer_list:\n",
    "            seq_list.append(seq)\n",
    "            pos_list.append(pos)\n",
    "    result = pd.DataFrame({'Seq':seq_list,'Position':pos_list,'Peak_Seq':Item})\n",
    "    return(result)\n",
    "\n",
    "\n",
    "def Score_Blaster(x, kmerSeqs,Thresh=Threshold, kmer_length = kmer_length):\n",
    "    \"\"\"Score_Blaster applies kmer_match to a dataframe. Only gives scores above a threshold, zip version\"\"\"\n",
    "    DataFrames = []\n",
    "    print('Total length: ' + str(len(x)))\n",
    "    for index,row in enumerate(zip(x['Sequence'], x['Position'])):\n",
    "      # Counter to keep track of progress\n",
    "      if int(index)%5000 == 0:\n",
    "        print(index)\n",
    "      # kmer match function \n",
    "      DataFrames.append(kmer_match(row[0], kmer_length, kmerSeqs,  row[1]))\n",
    "    result = pd.concat(DataFrames)\n",
    "    return(result)\n",
    "\n",
    "def Site_Caller(x):\n",
    "  \"\"\" Siter caller looks for consecutive overlaps \"\"\"\n",
    "  Groups = []\n",
    "  PrevPos = x['Position'][0] -1\n",
    "  PrevSeq = x['Peak_Seq'][0]\n",
    "  SeqNumber = 0\n",
    "  for idx,row in enumerate(zip(x['Peak_Seq'],x['Position'])):\n",
    "    # When a new Sequence is being read\n",
    "    if str(row[0]) != str(PrevSeq):\n",
    "      PrevSeq = str(row[0])\n",
    "      PrevPos = row[1]\n",
    "      SeqNumber = SeqNumber + 1\n",
    "      Groups.append(SeqNumber)\n",
    "    # When you have a consecutive position\n",
    "    elif row[1] - PrevPos == 1:\n",
    "      Groups.append(SeqNumber)\n",
    "      PrevPos = row[1]\n",
    "    # When you have a non-consecutive position\n",
    "    elif row[1] - PrevPos != 1:\n",
    "      PrevPos = row[1]\n",
    "      SeqNumber = SeqNumber + 1\n",
    "      Groups.append(SeqNumber)\n",
    "  return(Groups)\n",
    "\n",
    "\n",
    "def Chrom_Splitter(x):\n",
    "    \"\"\"Chrom_Splitter takes the concatinated names given in fasta outputs from bedtool's getfasta and turns them into bed compatible columns\"\"\"\n",
    "    Chrom = []\n",
    "    Start = []\n",
    "    End = []\n",
    "    for i in x.Peak_Seq:\n",
    "        i = i[1:-2]\n",
    "        cr = i.split(':')\n",
    "        pos = cr[1].split('-')\n",
    "        Chrom.append(cr[0])\n",
    "        Start.append(int(pos[0]))\n",
    "        End.append(int(pos[1]))\n",
    "    x['Chromosome'] = Chrom\n",
    "    x['Start'] = Start\n",
    "    x['End'] = End\n",
    "    return(x)\n",
    "\n",
    "def Genomic_Adjuster(x,orient, kmer_length=kmer_length):\n",
    "    g = x.groupby(by=['Peak_Seq', 'Site_number'])\n",
    "    Site_Start = []\n",
    "    Site_End = []\n",
    "    Chrom = []\n",
    "    Center = []\n",
    "    for name, group in g:\n",
    "        if orient == '+':\n",
    "            group_start = int(min(group.Position_x)) + int(group.Start.unique())\n",
    "            group_end = int(max(group.Position_x)) + int(group.Start.unique()) + kmer_length\n",
    "            group_center = (center_pos - int(min(group.kPosition))) + int(group.Start.unique()) + int(min(group.Position_x))\n",
    "            Site_Start.append(group_start)\n",
    "            Site_End.append(group_end)\n",
    "            Center.append(group_center)\n",
    "            Chrom.append(group.Chromosome.unique()[0])\n",
    "        elif orient == '-':\n",
    "            slength = int(group.Length.unique())\n",
    "            group_end = int(slength - min(group.Position_x)) + int(group.Start.unique())\n",
    "            group_start = int(slength - max(group.Position_x) - kmer_length) + int(group.Start.unique()) \n",
    "            group_center = (slength - (center_pos - int(min(group.kPosition)) + int(min(group.Position_x)))) + int(group.Start.unique()) +1\n",
    "            Site_Start.append(group_start)\n",
    "            Site_End.append(group_end)\n",
    "            Center.append(group_center)\n",
    "            Chrom.append(group.Chromosome.unique()[0])\n",
    "    result = pd.DataFrame({'Chromosome':Chrom, \"Start\":Site_Start,\n",
    "             'End':Site_End, 'Center':Center, 'Orient':orient})\n",
    "    print(f\"Orientation selected is: {orient}\")\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "########################\n",
    "# Prepare For getfasta #\n",
    "########################\n",
    "# Adjust the \"Off by 1\" issue from bedtools due to the start site being exclusionary\n",
    "\n",
    "\n",
    "#Bash_Input = IO_Folder + \"/Adjusted_peaks\" \n",
    "# Bash_Out = IO_Folder + '/PeaksWSeqs.fasta' # fasta implies the seq\n",
    "\n",
    "# Read CSV, filter for short seqs and duplicates, adjust coordinates\n",
    "pk_coord = pd.read_csv(os.path.join(IO_Folder, peak_coord_file), sep = '\\t', header = None, usecols=[0,1,2]) \n",
    "pk_coord = pk_coord[pk_coord[2]-pk_coord[1] > (kmer_length+Overlap_Req)].drop_duplicates() # filter out(?) short sequences the caller would have trouble with\n",
    "pk_coord[1] = pk_coord[1] -1 # Move back 1, adjust for bedtools getfasta (0-indexed)\n",
    "\n",
    "pk_coord_adj_file = os.path.join(IO_Folder, peak_coord_file.split(\".\")[0]+\"_0-indexed.bed\")\n",
    "pk_file = os.path.join(IO_Folder,peak_coord_file.split(\".\")[0]+\".fasta\")\n",
    "\n",
    "pk_coord.to_csv(pk_coord_adj_file, sep = '\\t', index = False, header = None) #Output to getfasta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f'bedtools getfasta -s -fi {genome_file} -bed {pk_coord_adj_file} > {pk_file} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (<ipython-input-2-8a46c1006d16>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-8a46c1006d16>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    in_dir = \"C:\\Users\\th184\\Box Sync\\Gordan Lab\\PRIORITY_score_caller\\input\\example\"\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "#* Data Analysis *#\n",
    "###################\n",
    "\n",
    "print(\"Reading Files...\")\n",
    "\n",
    "# Read fasta files\n",
    "PeaksWSeqs = pd.read_csv(Bash_Out, sep = '\\t', header=None)\n",
    "PeaksWSeqs = DF_fasta(PeaksWSeqs)\n",
    "PeaksWSeqs['Length'] = PeaksWSeqs['Sequence'].apply(lambda x: len(x))\n",
    "# Make a reverse complement of the sequences\n",
    "rc_PeaksWSeqs = PeaksWSeqs.copy(deep = True)\n",
    "rc_PeaksWSeqs['Sequence'] = rc_PeaksWSeqs['Sequence'].apply(lambda x: reverse_complement(x))\n",
    "# turn the kmers series into a set for fast lookup\n",
    "chosen_kmers = set(kmers['kmer'])\n",
    "# Big function of the analysis\n",
    "def PRIORITY_CALL(Sequences, orientation = '+'):\n",
    "    Scored = Score_Blaster(x=Sequences, kmerSeqs = chosen_kmers) #Score sites\n",
    "    Groups = Site_Caller(Scored) # Look for consecutive overlaps (consecutive in genome), groups are a unique value\n",
    "    Called = Scored.copy(deep = True) # make a copy\n",
    "    Called['Site_number'] = Groups # add overlap annotation to DF\n",
    "    print(\"Finding Overlaps...\")\n",
    "    # Get overlaps of sites with more than 1 consecutive overlap\n",
    "    values = Called.Site_number.value_counts() \n",
    "    Called = Called[Called.Site_number.isin(values.index[values.gt(Overlap_Req-1)])]\n",
    "    Called['Position'] = Called['Position'].apply(lambda x: int(x))\n",
    "    # Get the core kmers as a set. Core kmers are those that contain the core range\n",
    "    core_kmers = set(kmers[kmers['is_core']]['kmer'])\n",
    "    core_groups = []\n",
    "    # for each group, only keep it if it has a core kmer\n",
    "    for group in Called.groupby(by='Site_number'):\n",
    "        if len(set(group[1].Seq).intersection(core_kmers)) > 0:\n",
    "            core_groups.append(group[0])\n",
    "    # Get the core groups as a set, filter by core groups\n",
    "    core_groups = set(core_groups)\n",
    "    Called_core = Called[Called['Site_number'].isin(core_groups)]\n",
    "    # Add kPosition to the DF\n",
    "    Called2 = pd.merge(Called_core, kmers[['kmer','kPosition']], left_on = 'Seq', right_on='kmer')\n",
    "    Called2 = Called2.sort_values(by=['Site_number', 'Position'])\n",
    "    # Check that the kPosition is consecutive\n",
    "    def checkConsecutive(l): \n",
    "        return sorted(l) == l \n",
    "    con_groups = []\n",
    "    for group in Called2.groupby(by='Site_number'):\n",
    "        if checkConsecutive(list(group[1].kPosition)):\n",
    "            con_groups.append(group[0])\n",
    "    con_groups = set(con_groups)\n",
    "    Called2 = Called2[Called2['Site_number'].isin(con_groups)]\n",
    "    Called2 = pd.merge(Called2, PeaksWSeqs[['Position','Length']], left_on = 'Peak_Seq', right_on = 'Position')\n",
    "    Called3 = Chrom_Splitter(Called2)\n",
    "    final = Genomic_Adjuster(Called3, orient=orientation)\n",
    "    final = final.drop_duplicates()\n",
    "    return(final)\n",
    "# Run the function for positive and negative strands\n",
    "Positive = PRIORITY_CALL(PeaksWSeqs)\n",
    "Negative = PRIORITY_CALL(rc_PeaksWSeqs, orientation= '-')\n",
    "# Merge the results\n",
    "total = pd.concat([Positive,Negative])\n",
    "total['Start'] = total['Center']\n",
    "total['End'] = total['Center']\n",
    "total = total[['Chromosome', 'Start', 'End', 'Orient']]\n",
    "total.to_csv(f\"{IO_Folder}/Centered_PRIORITY.bed\", sep = '\\t', header = None, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.14.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
